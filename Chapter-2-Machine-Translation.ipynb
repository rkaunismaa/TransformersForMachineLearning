{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wednesday, June 21, 2023\n",
    "\n",
    "My walkthrough of the notebook ...\n",
    "\n",
    "[Chapter-2-Machine-Translation.ipynb](https://github.com/CRCTransformers/deepdive-book/blob/main/Chapter-2-Machine-Translation.ipynb)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Translation Comparison: Attention vs Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "\n",
    "startTime = time.time()\n",
    "todaysDate = date.today()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I always have so many issues with spacy??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python -m spacy download fr  ... this NEVER works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy.cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacyDownload = False\n",
    "if spacyDownload:\n",
    "    spacy.cli.download(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ecco\n",
    "# !pip install torchtext\n",
    "# !pip install wget\n",
    "\n",
    "# this would not work ... had to run outside of this container ...sigh\n",
    "# %%capture\n",
    "# !wget https://download.pytorch.org/tutorial/data.zip && unzip data.zip && rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from collections import Counter \n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import ecco\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 20\n",
    "FILTER_TO_BASIC_PREFIXES = False\n",
    "SAVE_DIR = os.path.join(\".\", \"models\")\n",
    "\n",
    "ENCODER_EMBEDDING_DIM = 256\n",
    "ENCODER_HIDDEN_SIZE = 256\n",
    "DECODER_EMBEDDING_DIM = 256\n",
    "DECODER_HIDDEN_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 21 18:43:23 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   59C    P0    N/A /  70W |    393MiB /  2048MiB |      9%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 24%   32C    P8     4W / 215W |      8MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/eng-fra.txt', encoding=\"utf-8\") as f:\n",
    "    lines = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135,842 English-French phrase pairs.\n",
      "\n",
      "~~~~~ Examples: ~~~~~\n",
      "English:  Don't jump to any conclusions.\n",
      "French:   Ne saute pas à de quelconques conclusions !\n",
      "\n",
      "English:  Get on with it.\n",
      "French:   Continue !\n",
      "\n",
      "English:  It's a good idea, to be sure, but it's hard to put it into practice.\n",
      "French:   C'est assurément une bonne idée, mais c'est difficile à mettre en pratique.\n",
      "\n",
      "English:  This guy's great at pitching curveballs.\n",
      "French:   Ce type est fort pour lancer des balles à trajectoire incurvée.\n",
      "\n",
      "English:  They're dancing.\n",
      "French:   Ils sont en train de danser.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(lines):,} English-French phrase pairs.\\n\")\n",
    "print(\"~~~~~ Examples: ~~~~~\")\n",
    "for example in random.choices(lines, k=5):\n",
    "    pair = example.split('\\t')\n",
    "    print(f\"English:  {pair[0]}\")\n",
    "    print(f\"French:   {pair[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    sReturn = ''.join( c for c in unicodedata.normalize(\"NFD\", s) if unicodedata.category(c) != 'Mn')\n",
    "    return sReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    sReturn = unicodeToAscii(s.lower().strip())\n",
    "    sReturn = re.sub(r\"[^a-zA-Z.!?]+\", \" \", sReturn)\n",
    "    return sReturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p, max_length, prefixes):\n",
    "\n",
    "    good_length = (len(p[0].split(' ')) < max_length) and (len(p[1].split(' ')) < max_length)\n",
    "    if len(prefixes)== 0 :\n",
    "        return good_length\n",
    "    else:\n",
    "        return good_length and p[0].startswith(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPairs(pairs, max_length, prefixes=()):\n",
    "    return [ pair for pair in pairs if filterPair(pair, max_length, prefixes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lines, filter=False, reverse=False, max_length=10, prefixes=()):\n",
    "\n",
    "    pairs = [ [normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    print(f\"Given {len(pairs):,} sentence pairs\")\n",
    "\n",
    "    if filter:\n",
    "        pairs = filterPairs(pairs, max_length=max_length, prefixes=prefixes)\n",
    "        print(f\"After filtering, {len(pairs):,} remain.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \",\n",
    "    'are you', 'am i ', \n",
    "    'were you', 'was i ', \n",
    "    'where are', 'where is',\n",
    "    'what is', 'what are'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given 135,842 sentence pairs\n",
      "After filtering, 135,284 remain.\n"
     ]
    }
   ],
   "source": [
    "pairs = prepareData(lines, \n",
    "                    filter=True, \n",
    "                    max_length=MAX_SENTENCE_LENGTH, \n",
    "                    prefixes=basic_prefixes if FILTER_TO_BASIC_PREFIXES else ())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Run Date: Wednesday, June 21, 2023\n",
      "# Run Time: 00:00:02\n"
     ]
    }
   ],
   "source": [
    "endTime = time.time()\n",
    "\n",
    "elapsedTime = time.strftime(\"%H:%M:%S\", time.gmtime(endTime - startTime))\n",
    "\n",
    "print(todaysDate.strftime('# Run Date: %A, %B %d, %Y'))\n",
    "print(f\"# Run Time: {elapsedTime}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

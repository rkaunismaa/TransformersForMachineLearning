{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wednesday, June 21, 2023\n",
    "\n",
    "My walkthrough of the notebook ...\n",
    "\n",
    "[Chapter-2-Machine-Translation.ipynb](https://github.com/CRCTransformers/deepdive-book/blob/main/Chapter-2-Machine-Translation.ipynb)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Translation Comparison: Attention vs Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import date\n",
    "\n",
    "startTime = time.time()\n",
    "todaysDate = date.today()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do I always have so many issues with spacy??"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!python -m spacy download fr  ... this NEVER works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import spacy.cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacyDownload = False\n",
    "if spacyDownload:\n",
    "    spacy.cli.download(\"fr_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ecco\n",
    "# !pip install torchtext\n",
    "# !pip install wget\n",
    "\n",
    "# this would not work ... had to run outside of this container ...sigh\n",
    "# %%capture\n",
    "# !wget https://download.pytorch.org/tutorial/data.zip && unzip data.zip && rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
    "from collections import Counter \n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import ecco\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = 20\n",
    "FILTER_TO_BASIC_PREFIXES = False\n",
    "SAVE_DIR = os.path.join(\".\", \"models\")\n",
    "\n",
    "ENCODER_EMBEDDING_DIM = 256\n",
    "ENCODER_HIDDEN_SIZE = 256\n",
    "DECODER_EMBEDDING_DIM = 256\n",
    "DECODER_HIDDEN_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun 21 19:23:59 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n",
      "|  0%   57C    P0    N/A /  70W |    454MiB /  2048MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce ...  On   | 00000000:02:00.0 Off |                  N/A |\n",
      "| 24%   32C    P8     4W / 215W |      8MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    !nvidia-smi\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/eng-fra.txt', encoding=\"utf-8\") as f:\n",
    "    lines = f.read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135,842 English-French phrase pairs.\n",
      "\n",
      "~~~~~ Examples: ~~~~~\n",
      "English:  I want to see if I can do that.\n",
      "French:   Je veux voir si je peux le faire.\n",
      "\n",
      "English:  We saw nothing strange.\n",
      "French:   Nous ne vîmes rien d'étrange.\n",
      "\n",
      "English:  There are a lot of dustballs under the couch.\n",
      "French:   Il y a beaucoup de moutons sous le canapé.\n",
      "\n",
      "English:  If you know the answer to this question, please tell me.\n",
      "French:   Si vous connaissez la réponse à cette question, dites-la-moi, s'il vous plait.\n",
      "\n",
      "English:  What's the world's highest mountain?\n",
      "French:   Quelle est la montagne la plus haute au monde ?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(lines):,} English-French phrase pairs.\\n\")\n",
    "print(\"~~~~~ Examples: ~~~~~\")\n",
    "for example in random.choices(lines, k=5):\n",
    "    pair = example.split('\\t')\n",
    "    print(f\"English:  {pair[0]}\")\n",
    "    print(f\"French:   {pair[1]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "      c for c in unicodedata.normalize('NFD', s) \n",
    "      if unicodedata.category(c) != 'Mn'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", \" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPair(p, max_length, prefixes):\n",
    "    good_length = (len(p[0].split(' ')) < max_length) and (len(p[1].split(' ')) < max_length)\n",
    "    if len(prefixes) == 0:\n",
    "        return good_length\n",
    "    else:\n",
    "        return good_length and p[0].startswith(prefixes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterPairs(pairs, max_length, prefixes=()):\n",
    "    return [pair for pair in pairs if filterPair(pair, max_length, prefixes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(lines, filter=False, reverse=False, max_length=10, prefixes=()):\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    print(f\"Given {len(pairs):,} sentence pairs.\")\n",
    "\n",
    "    if filter:\n",
    "        pairs = filterPairs(pairs, max_length=max_length, prefixes=prefixes)\n",
    "        print(f\"After filtering, {len(pairs):,} remain.\")\n",
    "\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \",\n",
    "    'are you', 'am i ', \n",
    "    'were you', 'was i ', \n",
    "    'where are', 'where is',\n",
    "    'what is', 'what are'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given 135,842 sentence pairs.\n",
      "After filtering, 135,284 remain.\n"
     ]
    }
   ],
   "source": [
    "pairs = prepareData(lines, \n",
    "                    filter=True, \n",
    "                    max_length=MAX_SENTENCE_LENGTH, \n",
    "                    prefixes=basic_prefixes if FILTER_TO_BASIC_PREFIXES else ())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The notebook from the authors repo shows 15, 593 remaining. Why do we get a different result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['go.', 'va !'],\n",
       " ['run!', 'cours !'],\n",
       " ['run!', 'courez !'],\n",
       " ['wow!', 'ca alors !'],\n",
       " ['fire!', 'au feu !'],\n",
       " ['help!', 'a l aide !'],\n",
       " ['jump.', 'saute.'],\n",
       " ['stop!', 'ca suffit !'],\n",
       " ['stop!', 'stop !'],\n",
       " ['stop!', 'arrete toi !']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Run Date: Wednesday, June 21, 2023\n",
      "# Run Time: 00:00:04\n"
     ]
    }
   ],
   "source": [
    "endTime = time.time()\n",
    "\n",
    "elapsedTime = time.strftime(\"%H:%M:%S\", time.gmtime(endTime - startTime))\n",
    "\n",
    "print(todaysDate.strftime('# Run Date: %A, %B %d, %Y'))\n",
    "print(f\"# Run Time: {elapsedTime}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
